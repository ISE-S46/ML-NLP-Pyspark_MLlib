{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Data"
      ],
      "metadata": {
        "id": "UoScASjkAT13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of Missing Data\n",
        "\n",
        "- Missing Completely at Random (MCAR) : The probability of missing data on a variable is unrelated to any other observed or unobserved variable. It's purely random.\n",
        "  - One man forgot to answer his weight\n",
        "  - Missing of IQ score does not depends on Age\n",
        "- Missing at Random (MAR) : The probability of missing data on a variable is related to some other observed variables but not the variable itself (Y depends on X).\n",
        "  - Women tend to not disclose their weight.\n",
        "  - The IQ score for people under 31 years old often doesn't have an answer.\n",
        "- Missing Not at Random (MNAR) : The probability of missing data on a variable is related to the values of that variable itself, even after controlling for other variables (Y depends on Y).\n",
        "  - People with more weight tend to not answer this question.\n",
        "  - People with low IQ score tend to not answer the question."
      ],
      "metadata": {
        "id": "l2hdkAbKAfwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RHN4_y4xh2LB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('missing data').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/oakabc/DEA/refs/heads/main/7%20-%20Missing%20Data%2C%20Dates%20and%20Timestamp/ContainsNull.csv\"\n",
        "response = requests.get(url)\n",
        "\n",
        "with open(\"ContainsNull.csv\", \"wb\") as file:\n",
        "   file.write(response.content)\n",
        "\n",
        "# Then read the local file\n",
        "df = spark.read.csv(\"ContainsNull.csv\", header=True, inferSchema=True)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5c2890pj0cI",
        "outputId": "19562a27-1849-4154-f4f7-fa58c1e9e9ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2| NULL| NULL|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpMo22A_krzZ",
        "outputId": "b17b9c32-5dfc-465f-a2d1-0906a939784f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sales: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop row(s) that contains NULL"
      ],
      "metadata": {
        "id": "iJx1pZU3BRdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OUMxyJplQfw",
        "outputId": "1835ef82-2e95-4092-e584-55d577ac0c75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop row(s) that contains NON-NULL that satisfy the threshold"
      ],
      "metadata": {
        "id": "oHcLJzAtBUMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXz2VFzhlRU_",
        "outputId": "8ca216f1-8cb8-490b-9f13-a39273afd419"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using How (all)**\n",
        "\n",
        "The how parameter in the df.na.drop() method specifies how rows or columns with missing (null) values should be handled in the DataFrame.\n",
        "\n",
        "By default, how='any' is used if the how parameter is not explicitly specified.\n",
        "\n",
        "how='all' means that only rows (or columns) where all values are null will be dropped.\n",
        "If a row (or column) has at least one non-null value, it will be retained."
      ],
      "metadata": {
        "id": "xTwryyn7BrFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(how='all').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bojqs_q5mdHh",
        "outputId": "45cbd3dc-17df-4765-cbcc-9db7d9a75f29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2| NULL| NULL|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using subset**\n",
        "\n",
        "The subset parameter in df.na.drop() specifies the columns that PySpark should check for null (or missing) values. Rows with null values in the specified subset of columns will be dropped.\n",
        "\n",
        "This command checks for null values only in the Sales column.\n",
        "If a row has a null value in the Sales column, it will be removed, even if other columns in the same row have valid (non-null) values."
      ],
      "metadata": {
        "id": "ee9_WZ_iB5gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(subset = ['Sales']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQQR1jkfmw5k",
        "outputId": "05f263a5-ce7a-40a4-e6cf-c42157637634"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill in the Missing Values**\n",
        "\n",
        "The method df.na.fill('yatta') fills missing (null) values only for columns with a data type of StringType because you are providing a string value ('yatta').\n",
        "PySpark automatically applies this value only to compatible column types."
      ],
      "metadata": {
        "id": "CgWjWzkiCDnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill('yatta').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd4Ra9MfnE2u",
        "outputId": "27b5323f-b11e-4d5e-8c69-958cdac05ae6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2|yatta| NULL|\n",
            "|emp3|yatta|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnqpTnrInP2_",
        "outputId": "228adc2a-13fa-45e9-da36-7ee831d64936"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John|  0.0|\n",
            "|emp2| NULL|  0.0|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the missing values in the selected columns"
      ],
      "metadata": {
        "id": "nR5IbajeCVbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill('yatta', subset = ['Name']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPqXu4RFn81b",
        "outputId": "9ca66d37-0a5c-4eef-edcc-eb215efa9142"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2|yatta| NULL|\n",
            "|emp3|yatta|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tests**"
      ],
      "metadata": {
        "id": "X1ot94pFqTbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill('yatta', subset = ['Name']).show()\n",
        "df.na.fill(69, subset = ['Sales']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jh7jWeipJRt",
        "outputId": "9bf2adb0-4bfc-4d7e-8ffa-49debaf95145"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2|yatta| NULL|\n",
            "|emp3|yatta|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n",
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| 69.0|\n",
            "|emp2| NULL| 69.0|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the missing values by means (Means Imputation)"
      ],
      "metadata": {
        "id": "vXdrPVliCgAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "mean_sales = df.select(mean(df['Sales'])).collect()\n",
        "mean_sales"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B28ONsgdouWZ",
        "outputId": "ecc7d983-07e9-474d-fdf5-cf2fbf1b1681"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(avg(Sales)=400.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract value from list"
      ],
      "metadata": {
        "id": "GjretCxUDB0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_sales = mean_sales[0][0]\n",
        "mean_sales"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvKOXdm3o7Ok",
        "outputId": "75693f03-694e-42f4-b4b9-8550fb96c037"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400.5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(mean_sales, ['Sales']).show()\n",
        "# df.na.fill(df.select(mean(df['Sales'])).collect()[0][0], ['Sales']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UW-t_DwpA20",
        "outputId": "9d138425-f4c4-452e-b237-5708747c5077"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John|400.5|\n",
            "|emp2| NULL|400.5|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "mean_sales = df.select(mean(df['Sales'])).collect()\n",
        "mean_sales\n",
        "\n",
        "df.na.fill('son', subset = ['Name']).show()\n",
        "\n",
        "mean_sales = mean_sales[0][0]\n",
        "mean_sales\n",
        "\n",
        "df.na.fill(mean_sales, ['Sales']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x018HbWoqDfM",
        "outputId": "7a1c6e54-393f-4b8d-b3b3-cb36669386d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John| NULL|\n",
            "|emp2|  son| NULL|\n",
            "|emp3|  son|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n",
            "+----+-----+-----+\n",
            "|  Id| Name|Sales|\n",
            "+----+-----+-----+\n",
            "|emp1| John|400.5|\n",
            "|emp2| NULL|400.5|\n",
            "|emp3| NULL|345.0|\n",
            "|emp4|Cindy|456.0|\n",
            "+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "MeBONrz4tkHn"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}